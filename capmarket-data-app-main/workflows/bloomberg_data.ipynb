{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c2551590-3542-4281-b807-e1203ceaa3a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Reading Bloomberg Data\n",
    "We'll be reading market data and company information from bloomberg data license. For that purpose, we created a wrapper atop of the data license API (see `bloomberg` package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e707bf32-555f-48f8-a562-a580c40e50e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dbd0c2c1-5087-4674-a342-6e40380bb9f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Read portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da0d0d88-ac18-4668-8bc5-7e23b4b60845",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lakehouse_catalog = 'financial_services'\n",
    "lakehouse_database = 'investment_analytics'\n",
    "bloomberg_entity_table = 'bloomberg_entity'\n",
    "bloomberg_history_table = 'bloomberg_prices'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e82f0b73-871b-49dd-a1a7-9d82f532c42c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('portfolio.json', 'r') as f:\n",
    "    portfolio = json.loads(f.read())\n",
    "\n",
    "with open('bloomberg_credentials.json', 'r') as f:\n",
    "    credentials = json.loads(f.read())\n",
    "\n",
    "catalog = '40372'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d1fd9a3-5fb4-4d3b-81d4-4da4039b010a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def build_symbol(symbol):\n",
    "    return {\n",
    "        \"@type\": \"Identifier\",\n",
    "        \"identifierValue\": symbol,\n",
    "        \"identifierType\": \"TICKER\"\n",
    "    }\n",
    "\n",
    "symbols = [build_symbol(rec['ticker']) for rec in portfolio]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff301095-2852-4d94-bd82-ec341612aed0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "output_dir = f'/Volumes/{lakehouse_catalog}/{lakehouse_database}/landing/bloomberg'\n",
    "if not os.path.exists(output_dir):\n",
    "  os.mkdir(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "980dfbfb-2270-4986-9e4d-3f5263a95af0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Download data from Bloomberg Data License\n",
    "\n",
    "`TODO`: Make sure to whitelist serverless IP range on Bloomberg `DATA<GO>` portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78d9e58d-649e-4b7d-8e78-0125977e4410",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from bloomberg.service import DataLicenseSvc, generate_unique_identifier\n",
    "\n",
    "service = DataLicenseSvc(credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2728a49c-115e-48f1-ab24-5ce2bd85dd32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Entity Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56587705-1768-4e2f-b92d-8f32fb1241f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "request_name = \"EntityRequest\" + str(uuid.uuid1())[:6]\n",
    "request_payload = {\n",
    "    '@type': 'EntityRequest',\n",
    "    'identifier': generate_unique_identifier(),\n",
    "    'name': request_name,\n",
    "    'description': 'Some description',\n",
    "    'universe': {\n",
    "        '@type': 'Universe',\n",
    "        'contains': symbols\n",
    "    },\n",
    "    'fieldList': {\n",
    "        '@type': 'EntityFieldList',\n",
    "        'contains': [\n",
    "            {'mnemonic': 'ID_BB_COMPANY'},\n",
    "            {'mnemonic': 'LEGAL_ENTITY_IDENTIFIER'},\n",
    "            {'mnemonic': 'LONG_COMP_NAME'},\n",
    "            {'mnemonic': 'CIE_DES'},\n",
    "            {'mnemonic': 'CNTRY_OF_DOMICILE'},\n",
    "            {'mnemonic': 'INDUSTRY_GROUP'},\n",
    "            {'mnemonic': 'INDUSTRY_SUBGROUP'},\n",
    "            {'mnemonic': 'BS_SH_OUT'}\n",
    "        ],\n",
    "    },\n",
    "    'trigger': {\n",
    "        \"@type\": \"SubmitTrigger\",\n",
    "    },\n",
    "    'formatting': {\n",
    "        '@type': 'MediaType',\n",
    "        'outputMediaType': 'application/json',\n",
    "    },\n",
    "}\n",
    "\n",
    "entityRequestIdentifier = service.submit_data_request(catalog=catalog, json_request=request_payload)\n",
    "entityRequestFile = service.await_response(identifier=entityRequestIdentifier)\n",
    "service.download_file(bloomberg_file=entityRequestFile, output_dir=output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f49ff2b-b122-4655-b70f-3fe7affe8cbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "@F.udf('string')\n",
    "def get_ticker(identifier):\n",
    "  # US equity only in that example portfolio\n",
    "  return '{}-US'.format(identifier.split(' ')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3e88956-e158-4492-953d-c80999f40e14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.format('json').load(entityRequestFile.output_dir).withColumn('TICKER', get_ticker(F.col('IDENTIFIER'))).drop('IDENTIFIER')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6349c049-e441-4323-8dbd-2586a829cb12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "_ = sql(f\"\"\"\n",
    "  CREATE TABLE IF NOT EXISTS {lakehouse_catalog}.{lakehouse_database}.{bloomberg_entity_table} (\n",
    "    BS_SH_OUT DOUBLE COMMENT 'Represents the balance sheet output value, which is a key financial metric for assessing the company\\\\'s financial position.',\n",
    "    CIE_DES STRING COMMENT 'Describes the name or designation of the company or entity involved in the transaction or record.',\n",
    "    CNTRY_OF_DOMICILE STRING COMMENT 'Indicates the country where the entity is legally domiciled, which can affect regulatory and tax considerations.',\n",
    "    DL_REQUEST_ID STRING COMMENT 'A unique identifier for the data loading request, useful for tracking and managing data ingestion processes.',\n",
    "    DL_REQUEST_NAME STRING COMMENT 'The name associated with the data loading request, providing context for the specific data operation being performed.',\n",
    "    DL_SNAPSHOT_START_TIME STRING COMMENT 'Marks the start time of the data snapshot, which is important for understanding the temporal context of the data.',\n",
    "    DL_SNAPSHOT_TZ STRING COMMENT 'Specifies the time zone of the snapshot start time, ensuring accurate interpretation of the timing of the data.',\n",
    "    ID_BB_COMPANY BIGINT COMMENT 'A unique identifier for the company within the system, essential for linking related data across different tables.',\n",
    "    INDUSTRY_GROUP STRING COMMENT 'Categorizes the company into a broader industry group, aiding in market analysis and benchmarking.',\n",
    "    INDUSTRY_SUBGROUP STRING COMMENT 'Further classifies the company into a specific subgroup within the industry, providing more granular insights.',\n",
    "    LEGAL_ENTITY_IDENTIFIER STRING COMMENT 'A standardized identifier for legal entities, which is crucial for compliance and regulatory reporting.',\n",
    "    LONG_COMP_NAME STRING COMMENT 'The full legal name of the company, which is important for formal documentation and identification.',\n",
    "    RC BIGINT COMMENT 'Represents a reference code or identifier that may be used for internal tracking or categorization purposes.',\n",
    "    TICKER STRING COMMENT 'A unique identifier for the record or entity (aka Ticker), facilitating easy reference and retrieval of specific data points.'\n",
    "  )\n",
    "  USING delta\n",
    "  COMMENT 'The table contains data related to companies and their financial metrics. It includes information such as the company\\\\'s identifier, legal entity identifier, industry classification, and various financial snapshots. Possible use cases include analyzing company performance, comparing industry trends, and tracking changes over time in financial metrics.'\n",
    "  \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2a99c2e-0669-4860-943d-1c8d9491397f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.write.mode('overwrite').saveAsTable(f'{lakehouse_catalog}.{lakehouse_database}.{bloomberg_entity_table}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "879fc51b-eec0-438d-8288-6be520e3aa0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### History Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96998cc0-df43-4871-937f-768a4b07cbb8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "request_name = \"HistoryRequest\" + str(uuid.uuid1())[:6]\n",
    "import datetime\n",
    "\n",
    "today = datetime.date.today()\n",
    "first = today.replace(day=1)\n",
    "last_month = first - relativedelta(months=1)\n",
    "request_payload = {\n",
    "    '@type': 'HistoryRequest',\n",
    "    'identifier': generate_unique_identifier(),\n",
    "    'name': request_name,\n",
    "    'description': 'My favorite history request',\n",
    "    'universe': {\n",
    "        '@type': 'Universe',\n",
    "        'contains': symbols,\n",
    "    },\n",
    "    'fieldList': {\n",
    "        '@type': 'HistoryFieldList',\n",
    "        'contains': [\n",
    "            # Returns the ask price received from the current pricing source. The ask price will always come from the date and time in Time Date of Last Update (PR024, LAST_UPDATE)/Date Of Last Update (PR371, LAST_UPDATE_DT). If there is no ask at that time but there was a valid bid then NA will be returned. If there is no bid and no ask at that time then the value will match Last Price (PR005, PX_LAST).\n",
    "            {'mnemonic': 'PX_ASK'},\n",
    "            # Returns the bid price received from the current pricing source. The bid price will always come from the date and time in Time Date of Last Update (PR024, LAST_UPDATE)/Date Of Last Update (PR371, LAST_UPDATE_DT). If there is no bid at that time but there was a valid ask then NA will be returned. If there is no bid and no ask at that time then the value will match Last Price (PR005, PX_LAST).\n",
    "            {'mnemonic': 'PX_BID'},\n",
    "            # Total number of shares traded on a security on the current day. If the security has not traded, then it is the total number of shares from the last day the security traded. If an exchange sends official closing price without a volume, the return will be '0'. If no closing price data is sent by the exchange, the return will reflect the last data received from the exchange. The pricing source in use must be set up to show volume, otherwise the field will return a blank. Expressed in units.\n",
    "            {'mnemonic': 'PX_VOLUME'},\n",
    "            # Price at which the security first traded on the current day. If the market is closed, it is the first price of the last day the market was open.\n",
    "            {'mnemonic': 'PX_OPEN'},\n",
    "            # Highest price the security reached during the current trading day. If the market is closed then it is the highest price the security reached on the last day the market was open.\n",
    "            {'mnemonic': 'PX_HIGH'},\n",
    "            # Lowest price the security reached during the current trading day. If the market is closed then it is the lowest price the security reached on the last day the market was open.\n",
    "            {'mnemonic': 'PX_LOW'},\n",
    "            # Returns the last price provided by the exchange. For securities that trade Monday through Friday, this field will be populated only if such information has been provided by the exchange in the past 30 trading days. For initial public offerings (IPO), the day before the first actual trading day may return the IPO price. For all other securities, this field will be populated only if such information was provided by the exchange in the last 30 calendar days. This applies to common stocks, receipts, warrants, and real estate investment trusts (REITs).\n",
    "            {'mnemonic': 'PX_LAST'},\n",
    "        ],\n",
    "    },\n",
    "    'trigger': {\n",
    "        '@type': 'SubmitTrigger'\n",
    "    },\n",
    "    'runtimeOptions': {\n",
    "        '@type': 'HistoryRuntimeOptions',\n",
    "        'dateRange': {\n",
    "            '@type': 'IntervalDateRange',\n",
    "            'startDate': last_month.strftime(\"%Y-%m-%d\"),\n",
    "            'endDate': first.strftime(\"%Y-%m-%d\")\n",
    "        },\n",
    "    },\n",
    "    'formatting': {\n",
    "        '@type': 'MediaType',\n",
    "        'outputMediaType': 'application/json',\n",
    "    },\n",
    "}\n",
    "\n",
    "historyRequestIdentifier = service.submit_data_request(catalog=catalog, json_request=request_payload)\n",
    "historyRequestFile = service.await_response(identifier=historyRequestIdentifier)\n",
    "service.download_file(bloomberg_file=historyRequestFile, output_dir=output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27ba36ba-0b79-435c-87ad-1eadb2d56f89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.format('json').load(historyRequestFile.output_dir).withColumn('TICKER', get_ticker(F.col('IDENTIFIER'))).drop('IDENTIFIER')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96ed2df9-1e67-421a-81a1-ee43a50c6f03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "_ = sql(f\"\"\"\n",
    "  CREATE TABLE IF NOT EXISTS {lakehouse_catalog}.{lakehouse_database}.{bloomberg_history_table} (\n",
    "    DATE STRING COMMENT 'Represents the date associated with the data entry, providing context for the time period of the records.',\n",
    "    DL_REQUEST_ID STRING COMMENT 'A unique identifier for each data loading request, useful for tracking and referencing specific requests.',\n",
    "    DL_REQUEST_NAME STRING COMMENT 'The name assigned to the data loading request, which can help in identifying the purpose or source of the data.',\n",
    "    DL_SNAPSHOT_START_TIME STRING COMMENT 'Indicates the start time of the data snapshot, essential for understanding the timeframe of the data collected.',\n",
    "    DL_SNAPSHOT_TZ STRING COMMENT 'Specifies the time zone of the snapshot start time, ensuring accurate interpretation of the timing data.',\n",
    "    PX_ASK DOUBLE COMMENT 'The asking price for the asset, representing the lowest price a seller is willing to accept.',\n",
    "    PX_BID DOUBLE COMMENT 'The bidding price for the asset, indicating the highest price a buyer is willing to pay.',\n",
    "    PX_HIGH DOUBLE COMMENT 'The highest price reached by the asset during the specified time period, useful for assessing market performance.',\n",
    "    PX_LAST DOUBLE COMMENT 'The last recorded price of the asset, providing the most recent market value.',\n",
    "    PX_LOW DOUBLE COMMENT 'The lowest price recorded for the asset during the specified time period, important for understanding market volatility.',\n",
    "    PX_OPEN DOUBLE COMMENT 'The opening price of the asset at the beginning of the specified time period, serving as a reference point for price movement.',\n",
    "    PX_VOLUME BIGINT COMMENT 'The total volume of the asset traded during the specified time period, indicating market activity and liquidity.',\n",
    "    RC BIGINT COMMENT 'Represents a record count or a related metric, which can be useful for data validation and analysis.',\n",
    "    TICKER STRING COMMENT 'A unique identifier for the record or entity (aka Ticker), facilitating easy reference and retrieval of specific data points.')\n",
    "USING delta\n",
    "COMMENT 'The table contains data related to financial market transactions, specifically focusing on price and volume metrics for various securities. It includes information such as the date of the transaction, request identifiers, and various price points (open, high, low, last, ask, and bid). This data can be used for analyzing market trends, evaluating security performance, and conducting price comparisons over time.'\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "973d3702-be12-4bca-bd86-225a106e4417",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.write.mode('overwrite').saveAsTable(f'{lakehouse_catalog}.{lakehouse_database}.{bloomberg_history_table}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b022faa9-7490-4fa0-89a6-2f35ab0eb24e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create a Genie space\n",
    "Simplistic example with really small subset of data, but great exercise to showcase genie being used as a tool in a multi agent model. Unfortunately, MCP servers are only available on playground for now and not accessible through agent notebook (hence databricks apps). Instead, we use the Genie API that we wrap behind langchain `@tool` decorator."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4713754764514104,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "bloomberg_data",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
